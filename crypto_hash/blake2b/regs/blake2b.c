/*
   BLAKE2 reference source code package - reference C implementations

   Written in 2012 by Samuel Neves <sneves@dei.uc.pt>

   To the extent possible under law, the author(s) have dedicated all copyright
   and related and neighboring rights to this software to the public domain
   worldwide. This software is distributed without any warranty.

   You should have received a copy of the CC0 Public Domain Dedication along with
   this software. If not, see <http://creativecommons.org/publicdomain/zero/1.0/>.
*/

#include "crypto_hash.h"
#include <stdint.h>
#include <string.h>
#include <stdio.h>

#define ROTR64(x, c) (((x) >> (c)) | ((x) << (64-(c))))

static void store64( void *dst, uint64_t w )
{
#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
  *( uint64_t * )( dst ) = w;
#else
  uint8_t *p = ( uint8_t * )dst;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w; w >>= 8;
  *p++ = ( uint8_t )w;
#endif
}

static uint64_t load64( const void *src )
{
#if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
  return *( uint64_t * )( src );
#else
  const uint8_t *p = ( uint8_t * )src;
  uint64_t w = *p++;
  w |= ( uint64_t )( *p++ ) <<  8;
  w |= ( uint64_t )( *p++ ) << 16;
  w |= ( uint64_t )( *p++ ) << 24;
  w |= ( uint64_t )( *p++ ) << 32;
  w |= ( uint64_t )( *p++ ) << 40;
  w |= ( uint64_t )( *p++ ) << 48;
  w |= ( uint64_t )( *p++ ) << 56;
  return w;
#endif
}

int crypto_hash(unsigned char *out, const unsigned char *in, unsigned long long inlen)
{
  uint64_t v0, v1, v2, v3, v4, v5, v6, v7;
  uint64_t v8, v9, v10, v11, v12, v13, v14, v15;
  uint64_t ctr = 0;

  v0 = 0x6a09e667f3bcc908ULL ^ 0x0000000001010040ULL;
  v1 = 0xbb67ae8584caa73bULL;
  v2 = 0x3c6ef372fe94f82bULL;
  v3 = 0xa54ff53a5f1d36f1ULL;
  v4 = 0x510e527fade682d1ULL;
  v5 = 0x9b05688c2b3e6c1fULL;
  v6 = 0x1f83d9abfb41bd6bULL;
  v7 = 0x5be0cd19137e2179ULL;

  while(inlen > 128)
  {
    const uint64_t m0  = load64(in + 0);
    const uint64_t m1  = load64(in + 8);
    const uint64_t m2  = load64(in + 16);
    const uint64_t m3  = load64(in + 24);
    const uint64_t m4  = load64(in + 32);
    const uint64_t m5  = load64(in + 40);
    const uint64_t m6  = load64(in + 48);
    const uint64_t m7  = load64(in + 56);
    const uint64_t m8  = load64(in + 64);
    const uint64_t m9  = load64(in + 72);
    const uint64_t m10 = load64(in + 80);
    const uint64_t m11 = load64(in + 88);
    const uint64_t m12 = load64(in + 96);
    const uint64_t m13 = load64(in + 104);
    const uint64_t m14 = load64(in + 112);
    const uint64_t m15 = load64(in + 120);

    const uint64_t iv0 = v0;
    const uint64_t iv1 = v1;
    const uint64_t iv2 = v2;
    const uint64_t iv3 = v3;
    const uint64_t iv4 = v4;
    const uint64_t iv5 = v5;
    const uint64_t iv6 = v6;
    const uint64_t iv7 = v7;

    ctr += 128;

    v8  = 0x6a09e667f3bcc908ULL;
    v9  = 0xbb67ae8584caa73bULL;
    v10 = 0x3c6ef372fe94f82bULL;
    v11 = 0xa54ff53a5f1d36f1ULL;
    v12 = 0x510e527fade682d1ULL ^ ctr;
    v13 = 0x9b05688c2b3e6c1fULL;
    v14 = 0x1f83d9abfb41bd6bULL;
    v15 = 0x5be0cd19137e2179ULL;

    v0 = v0 + v4 + m0; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m1; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m2; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m3; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m4; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m5; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m7; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m8; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m9; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m10; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m11; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m12; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m13; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m14; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m15; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m14; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m10; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m4; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m8; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m9; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m15; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m13; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m1; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m12; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m0; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m2; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m11; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m7; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m5; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m3; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m11; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m8; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m12; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m0; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m5; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m2; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m15; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m13; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m10; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m14; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m3; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m6; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m7; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m1; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m9; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m4; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m7; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m9; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m3; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m1; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m13; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m12; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m11; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m14; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m2; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m6; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m5; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m10; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m4; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m0; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m15; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m8; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m9; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m0; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m5; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m7; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m2; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m4; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m10; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m15; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m14; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m1; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m11; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m12; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m6; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m8; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m3; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m13; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m2; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m12; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m6; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m10; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m0; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m11; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m8; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m3; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m4; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m13; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m7; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m5; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m15; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m14; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m1; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m9; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m12; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m5; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m1; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m15; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m14; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m13; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m4; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m10; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m0; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m7; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m6; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m3; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m9; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m2; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m8; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m11; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m13; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m11; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m7; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m14; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m12; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m1; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m3; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m9; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m5; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m0; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m15; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m4; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m8; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m6; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m2; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m10; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m6; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m15; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m14; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m9; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m11; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m3; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m0; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m8; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m12; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m2; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m13; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m7; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m1; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m4; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m10; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m5; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m10; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m2; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m8; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m4; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m7; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m6; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m1; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m5; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m15; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m11; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m9; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m14; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m3; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m12; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m13; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m0; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m0; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m1; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m2; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m3; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m4; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m5; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m7; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m8; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m9; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m10; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m11; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m12; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m13; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m14; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m15; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m14; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m10; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m4; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m8; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m9; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m15; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m13; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m1; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m12; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m0; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m2; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m11; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m7; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m5; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m3; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 

    v0 = v0 ^  v8 ^ iv0;
    v1 = v1 ^  v9 ^ iv1;
    v2 = v2 ^ v10 ^ iv2;
    v3 = v3 ^ v11 ^ iv3;
    v4 = v4 ^ v12 ^ iv4;
    v5 = v5 ^ v13 ^ iv5;
    v6 = v6 ^ v14 ^ iv6;
    v7 = v7 ^ v15 ^ iv7;

    inlen -= 128;
    in += 128;
  }

  do
  {
    uint8_t buffer[128] = {0};
    memcpy(buffer, in, inlen);
    const uint64_t m0  = load64(buffer + 0);
    const uint64_t m1  = load64(buffer + 8);
    const uint64_t m2  = load64(buffer + 16);
    const uint64_t m3  = load64(buffer + 24);
    const uint64_t m4  = load64(buffer + 32);
    const uint64_t m5  = load64(buffer + 40);
    const uint64_t m6  = load64(buffer + 48);
    const uint64_t m7  = load64(buffer + 56);
    const uint64_t m8  = load64(buffer + 64);
    const uint64_t m9  = load64(buffer + 72);
    const uint64_t m10 = load64(buffer + 80);
    const uint64_t m11 = load64(buffer + 88);
    const uint64_t m12 = load64(buffer + 96);
    const uint64_t m13 = load64(buffer + 104);
    const uint64_t m14 = load64(buffer + 112);
    const uint64_t m15 = load64(buffer + 120);

    const uint64_t iv0 = v0;
    const uint64_t iv1 = v1;
    const uint64_t iv2 = v2;
    const uint64_t iv3 = v3;
    const uint64_t iv4 = v4;
    const uint64_t iv5 = v5;
    const uint64_t iv6 = v6;
    const uint64_t iv7 = v7;

    ctr += inlen;

    v8  = 0x6a09e667f3bcc908ULL;
    v9  = 0xbb67ae8584caa73bULL;
    v10 = 0x3c6ef372fe94f82bULL;
    v11 = 0xa54ff53a5f1d36f1ULL;
    v12 = 0x510e527fade682d1ULL ^ ctr;
    v13 = 0x9b05688c2b3e6c1fULL;
    v14 = ~0x1f83d9abfb41bd6bULL;
    v15 = 0x5be0cd19137e2179ULL;

    v0 = v0 + v4 + m0; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m1; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m2; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m3; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m4; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m5; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m7; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m8; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m9; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m10; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m11; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m12; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m13; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m14; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m15; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m14; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m10; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m4; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m8; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m9; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m15; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m13; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m1; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m12; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m0; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m2; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m11; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m7; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m5; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m3; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m11; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m8; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m12; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m0; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m5; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m2; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m15; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m13; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m10; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m14; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m3; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m6; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m7; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m1; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m9; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m4; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m7; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m9; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m3; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m1; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m13; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m12; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m11; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m14; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m2; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m6; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m5; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m10; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m4; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m0; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m15; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m8; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m9; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m0; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m5; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m7; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m2; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m4; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m10; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m15; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m14; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m1; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m11; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m12; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m6; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m8; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m3; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m13; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m2; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m12; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m6; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m10; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m0; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m11; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m8; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m3; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m4; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m13; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m7; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m5; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m15; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m14; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m1; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m9; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m12; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m5; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m1; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m15; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m14; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m13; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m4; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m10; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m0; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m7; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m6; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m3; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m9; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m2; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m8; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m11; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m13; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m11; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m7; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m14; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m12; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m1; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m3; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m9; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m5; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m0; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m15; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m4; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m8; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m6; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m2; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m10; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m6; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m15; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m14; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m9; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m11; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m3; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m0; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m8; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m12; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m2; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m13; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m7; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m1; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m4; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m10; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m5; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m10; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m2; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m8; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m4; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m7; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m6; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m1; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m5; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m15; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m11; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m9; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m14; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m3; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m12; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m13; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m0; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m0; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m1; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m2; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m3; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m4; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m5; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m7; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m8; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m9; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m10; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m11; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m12; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m13; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m14; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m15; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 
    v0 = v0 + v4 + m14; 
    v12 = ROTR64(v12 ^ v0, 32); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 24); 
    v0 = v0 + v4 + m10; 
    v12 = ROTR64(v12 ^ v0, 16); 
    v8 = v8 + v12; 
    v4 = ROTR64(v4 ^ v8, 63); 
    v1 = v1 + v5 + m4; 
    v13 = ROTR64(v13 ^ v1, 32); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 24); 
    v1 = v1 + v5 + m8; 
    v13 = ROTR64(v13 ^ v1, 16); 
    v9 = v9 + v13; 
    v5 = ROTR64(v5 ^ v9, 63); 
    v2 = v2 + v6 + m9; 
    v14 = ROTR64(v14 ^ v2, 32); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 24); 
    v2 = v2 + v6 + m15; 
    v14 = ROTR64(v14 ^ v2, 16); 
    v10 = v10 + v14; 
    v6 = ROTR64(v6 ^ v10, 63); 
    v3 = v3 + v7 + m13; 
    v15 = ROTR64(v15 ^ v3, 32); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 24); 
    v3 = v3 + v7 + m6; 
    v15 = ROTR64(v15 ^ v3, 16); 
    v11 = v11 + v15; 
    v7 = ROTR64(v7 ^ v11, 63); 
    v0 = v0 + v5 + m1; 
    v15 = ROTR64(v15 ^ v0, 32); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 24); 
    v0 = v0 + v5 + m12; 
    v15 = ROTR64(v15 ^ v0, 16); 
    v10 = v10 + v15; 
    v5 = ROTR64(v5 ^ v10, 63); 
    v1 = v1 + v6 + m0; 
    v12 = ROTR64(v12 ^ v1, 32); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 24); 
    v1 = v1 + v6 + m2; 
    v12 = ROTR64(v12 ^ v1, 16); 
    v11 = v11 + v12; 
    v6 = ROTR64(v6 ^ v11, 63); 
    v2 = v2 + v7 + m11; 
    v13 = ROTR64(v13 ^ v2, 32); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 24); 
    v2 = v2 + v7 + m7; 
    v13 = ROTR64(v13 ^ v2, 16); 
    v8 = v8 + v13; 
    v7 = ROTR64(v7 ^ v8, 63); 
    v3 = v3 + v4 + m5; 
    v14 = ROTR64(v14 ^ v3, 32); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 24); 
    v3 = v3 + v4 + m3; 
    v14 = ROTR64(v14 ^ v3, 16); 
    v9 = v9 + v14; 
    v4 = ROTR64(v4 ^ v9, 63); 

    v0 = v0 ^  v8 ^ iv0;
    v1 = v1 ^  v9 ^ iv1;
    v2 = v2 ^ v10 ^ iv2;
    v3 = v3 ^ v11 ^ iv3;
    v4 = v4 ^ v12 ^ iv4;
    v5 = v5 ^ v13 ^ iv5;
    v6 = v6 ^ v14 ^ iv6;
    v7 = v7 ^ v15 ^ iv7;

    store64(out +  0, v0);
    store64(out +  8, v1);
    store64(out + 16, v2);
    store64(out + 24, v3);
    store64(out + 32, v4);
    store64(out + 40, v5);
    store64(out + 48, v6);
    store64(out + 56, v7);
  } while(0);
  return 0;
}

#if defined(BLAKE2B_SELFTEST)
#include <string.h>
#include "blake2.h"
#include "blake2-kat.h"
int main( int argc, char **argv )
{
  uint8_t key[BLAKE2B_KEYBYTES];
  uint8_t buf[KAT_LENGTH];
  size_t i;

  for( i = 0; i < BLAKE2B_KEYBYTES; ++i )
    key[i] = ( uint8_t )i;

  for( i = 0; i < KAT_LENGTH; ++i )
    buf[i] = ( uint8_t )i;

  for( i = 0; i < KAT_LENGTH; ++i )
  {
    uint8_t hash[BLAKE2B_OUTBYTES];
    crypto_hash(hash, buf, i);

    if( 0 != memcmp( hash, blake2b_kat[i], BLAKE2B_OUTBYTES ) )
    {
      puts( "error" );
      return -1;
    }
  }

  puts( "ok" );
  return 0;
}
#endif

